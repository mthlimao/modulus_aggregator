import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import click
import numpy as np
import pandas as pd
from pathlib import Path
from tensorflow.python.summary.summary_iterator import summary_iterator
from modulus_aggregator.constants import RUN_PATH_NOT_FOUND, EXPORT_ERROR, WIDE_DF_NOT_POSSIBLE


@click.group()
def export():
    """Group of commands 'export'."""
    pass


@export.command()
@click.option('-mp', '--models_path', type=click.Path(exists=True), nargs=1, required=True,
              help="Path where the Modulus' experiment models are saved. "
                   "Each subpath of the experiment path will be related to a single run. " 
                   "The experiment path could be, for example, the 'outputs' or " 
                   "the 'multirun' directories generated by Modulus. "
                   "For now, this option is mandatory.")
@click.option('--export_pivot', is_flag=True,
              help="Option that enables exporting .csv file in pivoted (wide) form. "
                   "In case it's not possible to export in pivoted form, file is then "
                   "exported in standard format.")
@click.option('-et', '--export_training', is_flag=True, default=False,
              help="Option that bounds the aggregator to only export training related "
                   "tensors in the output .csv file. "
                   "This option can be used together with the other similar tags "
                   "(--export_validation and --export_monitoring). "
                   "If there is no detected training tensors, "
                   "the command will warn the user and proceed as possible.")
@click.option('-ev', '--export_validation', is_flag=True, default=False,
              help="Option that bounds the aggregator to only export validation related "
                   "tensors in the output .csv file. "
                   "This option can be used together with the other similar tags "
                   "(--export_training and --export_monitoring). "
                   "If there is no detected validation tensors, "
                   "the command will warn the user and proceed as possible.")
@click.option('-em', '--export_monitoring', is_flag=True, default=False,
              help="Option that bounds the aggregator to only export monitoring related "
                   "tensors in the output .csv file. "
                   "This option can be used together with the other similar tags "
                   "(--export_training and --export_validation). "
                   "If there is no detected monitoring tensors, "
                   "the command will warn the user and proceed as possible.")
def tensors(models_path, export_pivot, export_training, export_validation, export_monitoring):
    """
    This command export the registered tensors in a .csv file.
    """
    try:
        df_tensors = None
        models_path = Path(models_path).resolve(strict=True)
        filter_tensors_type, filtered_tensors_type = [], []
        output_file_name = f'{models_path.name}_tensors'

        # Define tags the user chose to filter
        if export_training or export_validation or export_monitoring:
            if export_training:
                filter_tensors_type.append('Train')
            if export_validation:
                filter_tensors_type.append('Validators')
            if export_monitoring:
                filter_tensors_type.append('Monitors')

        # Define name of output file
        for filter_tensor in filter_tensors_type:
            output_file_name = output_file_name + f'_{filter_tensor.lower()}'
        
        # Create tensors dataframe
        for run in os.listdir(models_path):
            run_path = models_path / run            
            if run_path.is_dir():
                click.echo(f'Exporting tensors for {run_path.name}...')

                df_run = write_to_dataframe(run_path, filter_tensors_type)
                df_tensors = pd.concat([df_tensors, df_run], axis=0) if df_tensors is not None else df_run
            
        tensor_tags_unique_lst = np.unique(df_tensors.loc[:, 'tag'].values)

        # Check what were the filtered tags and store them in filtered_tensors_type variable
        for filter_tensor in filter_tensors_type:
            for tensor_tag in tensor_tags_unique_lst:
                if filter_tensor in tensor_tag:
                    filtered_tensors_type.append(filter_tensor)
                    break

        # Compare actually filtered tags with tags the user chose to be filtered and print the difference in both sets
        if set(filter_tensors_type) != set(filtered_tensors_type):
            click.echo(f"The following tensors types were not found in models: {', '.join(list(set(filter_tensors_type) - set(filtered_tensors_type)))}.")

        # Handle data exportation
        if not export_pivot:
            df_tensors.to_csv(models_path / f'{output_file_name}.csv', index=False, sep=';')
        else:
            df_tensors_wide = return_pivoted_dataframe(df_tensors)
            if df_tensors_wide.shape == df_tensors.shape:
                click.echo(WIDE_DF_NOT_POSSIBLE)
                df_tensors.to_csv(models_path / f'{output_file_name}.csv', index=False, sep=';')
            else:
                df_tensors_wide.to_csv(models_path / f'{output_file_name}_pivoted.csv', index=False, sep=';')
        
        click.echo('Tensors successfully exported.')
        
    except FileNotFoundError:
        click.echo(RUN_PATH_NOT_FOUND)
    
    except:
        click.echo(EXPORT_ERROR)


def write_to_dataframe(run_path, filter_tensors_type):
    # Iterate through tensors
    tensors_dict = {
        'run' : [],
        'tag' : [],
        'step' : [],
        'value' : [],
        'wall_time' : [],
    }
    
    if type(filter_tensors_type) != list:
        filter_tensors_type = []

    # Get biggest events.tf file
    event_file = ""
    max_size = 0
    event_files_lst = [file for file in os.listdir(run_path) if 'events.out.tfevents' in file]
    for ef in event_files_lst:
        size = (run_path / ef).stat().st_size
        if size > max_size:
            max_size = size
            event_file = ef

    # Create dataframe
    tag_in_filter = True
    path_to_events_file = run_path / event_file
    for e in summary_iterator(path_to_events_file.as_posix()):
        for v in e.summary.value:
            if len(v.tensor.float_val) > 0:
                if len(filter_tensors_type) > 0:
                    tag_in_filter = False
                    for filter_tensor in filter_tensors_type:
                        if filter_tensor in v.tag:
                            tag_in_filter = True
                
                if tag_in_filter:
                    tensors_dict['run'].append(run_path.name)
                    tensors_dict['tag'].append(v.tag)
                    tensors_dict['step'].append(e.step)
                    tensors_dict['value'].append(v.tensor.float_val[0])
                    tensors_dict['wall_time'].append(e.wall_time)
    
    df_tensors = pd.DataFrame(tensors_dict)

    return df_tensors


def return_pivoted_dataframe(df_tensors):
    # Pivot dataframe
    dfw_data_dict = {'run': [], 'step': [], 'wall_time':[]}
    dfw = pd.DataFrame(dfw_data_dict)

    for tag in df_tensors["tag"].unique():
        df_tag = df_tensors[df_tensors['tag'] == tag]

        if dfw.shape[0] == 0:
            dfw['run'] = df_tag.loc[:, 'run']
            dfw['step'] = df_tag.loc[:, 'step']
            dfw['wall_time'] = df_tag.loc[:, 'wall_time']
        
        if df_tag.loc[:, 'value'].values.shape[0] == dfw.shape[0]:
            dfw[tag] = df_tag.loc[:, 'value'].values
        else:            
            return df_tensors
    
    return dfw
